{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding AWK\n",
    "\n",
    "\n",
    "Exercises taken from a variety of different sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "\n",
    "_I'll use `awk`, AWK, awk interchangeably in this tutorial._\n",
    "\n",
    "<hr>\n",
    "\n",
    "# <center> ! </center>\n",
    "\n",
    "If you're looking for a more simple approach for text/pattern processing (searching, replacing, extracting) I'd recommend to stick to `grep`. \n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "#### How does AWK work?\n",
    "\n",
    "Firs ot all `awk` isn't just a function (or a tool) but a programming language. It can process instructions as simple or as complex as we want; it has a steep learning curve and I don't recommend to try learning how to deeply use it unless you have a strong reason (or unless you're stubborn, like me). \n",
    "\n",
    "AWK works best with formatted text (ie, tables) that have a delimited number of columns and use the same separator (ie, comma for CSV files, tab for TSV). \n",
    "\n",
    "It works by reading one line at a time, performs an operation and prints a result to screen. \n",
    "\n",
    "On each line it separates the columns based on a character (ie., comma, space or tab) and assigns each column to a variable: `${N}` (N is a number between 1 and the total number of columns in the table).\n",
    "\n",
    "Let's start by looking at a simple table: first column are the row names, then from each column on different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "rowB\t2\t7\t10\r\n",
      "file3\t3\t6\t20\r\n",
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n"
     ]
    }
   ],
   "source": [
    "head cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "4\r\n",
      "12\r\n",
      "15\r\n"
     ]
    }
   ],
   "source": [
    "# A simple instruction: print only values from column 2\n",
    "awk '{print $2}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r\n",
      "3\r\n",
      "4\r\n",
      "12\r\n",
      "15\r\n"
     ]
    }
   ],
   "source": [
    "# In this example we assume there is no header (column names) in the table. \n",
    "# If the table had column names we can add an instruction to skip the first `n` lines.\n",
    "\n",
    "awk 'NR>1 {print $2}' cols.txt #Skips the first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "rowB\t2\t7\t10\r\n",
      "file3\t3\t6\t20\r\n",
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n"
     ]
    }
   ],
   "source": [
    "## The field (column) variable is indicated by the symbol $. A value of 0 means the whole line.\n",
    "# In this example, although we cannot see it, awk actually prints line by line instead of the\n",
    "# whole table like `cat` does.\n",
    "\n",
    "awk '{print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA 1\r\n",
      "rowB 7\r\n",
      "file3 6\r\n",
      "file4 5\r\n",
      "line_a 13\r\n",
      "line_b 16\r\n"
     ]
    }
   ],
   "source": [
    "# Print the first and third columns:\n",
    "awk '{print $1,$3}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\r\n",
      "rowB\t7\r\n",
      "file3\t6\r\n",
      "file4\t5\r\n",
      "line_a\t13\r\n",
      "line_b\t16\r\n"
     ]
    }
   ],
   "source": [
    "# Print the first and third columns separated by a tab\n",
    "awk '{print $1 \"\\t\" $3}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA,1,9\r\n",
      "rowB,7,10\r\n",
      "file3,6,20\r\n",
      "file4,5,99\r\n",
      "line_a,13,144\r\n",
      "line_b,16,177\r\n"
     ]
    }
   ],
   "source": [
    "# Print the 1st,3rd and 4th columns separated by a comma (useful to create csv tables)\n",
    "awk '{print $1 \",\" $3\",\"$4}' cols.txt # The spacing in the commands doesn't matter much, but \n",
    "# using spaces helps to keep things tidy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regex (regular expressions)\n",
    "\n",
    "*they can save your life (and make you look cool!) <sup>[citation needed]</sup>*\n",
    "\n",
    "https://www.xkcd.com/208/\n",
    "\n",
    "\\- - - <br>\n",
    "\n",
    "Print lines that match a pattern.\n",
    "\n",
    "Some basic rules:\n",
    "\n",
    "* The pattern goes in between forward dashes: /pattern/\n",
    "* `^pattern` looks for a exact match at the START of the text\n",
    "* `pattern$` looks for a exact match at the END of the text\n",
    "* `p[abc]ttern` looks for **a** or **b** or **c** in between *p* and *ttern*\n",
    "    * Possible matches would be: pattern,pbttern,pcttern \n",
    "    * but not combinations of any of the letterns in the brackets: <strike>p**ab**ttern, p**bc**ttern</strike>\n",
    "* `pat1|pat2` matches either pattern separated by the vertical line.\n",
    "\n",
    "https://www.digitalocean.com/community/tutorials/using-grep-regular-expressions-to-search-for-text-patterns-in-linux\n",
    "\n",
    "https://www.cheatography.com/davechild/cheat-sheets/regular-expressions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_a\t12\t13\t144\r\n"
     ]
    }
   ],
   "source": [
    "# If the first column has an 'a' (anywhere)\n",
    "awk '$1 ~ /a/ {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_a\t12\t13\t144\r\n"
     ]
    }
   ],
   "source": [
    "# We can also omit the print command. By default awk needs to print something.\n",
    "# if left unspecificed, it will print the whole line.\n",
    "awk '$1 ~ /a/' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "rowB\t2\t7\t10\r\n"
     ]
    }
   ],
   "source": [
    "# Look for an \"r\" at the START of the text:\n",
    "awk '$1 ~ /^r/' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_a\t12\t13\t144\r\n"
     ]
    }
   ],
   "source": [
    "# The pattern rules are pretty much the same for any other regex functions (grep, perl, R)\n",
    "awk '$1 ~ /a$/' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file3\t3\t6\t20\r\n",
      "file4\t4\t5\t99\r\n"
     ]
    }
   ],
   "source": [
    "# We can negate a match with !~\n",
    "# 'Print rows that don't contain w or n:\n",
    "awk '$1 !~ /[wn]/' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 20\r\n",
      "4 99\r\n"
     ]
    }
   ],
   "source": [
    "## And print specific columns\n",
    "# 'Print the 2nd and 4th columns of rows that don't contain w or n:\n",
    "awk '$1 !~ /[wn]/ {print $2,$4}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "file4\t4\t5\t99\r\n"
     ]
    }
   ],
   "source": [
    "## A wide search\n",
    "# Print rows that contain a 9 in ANY column\n",
    "awk '/9/ {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowB\t2\t7\t10\r\n",
      "file3\t3\t6\t20\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n"
     ]
    }
   ],
   "source": [
    "## A wide search can also be negated\n",
    "# Print rows that DON'T contain a 9 in ANY column\n",
    "awk '!/9/ {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### exact matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file4\t4\t5\t99\r\n"
     ]
    }
   ],
   "source": [
    "## Using == we can look for columns that have an EXACT match. \n",
    "# Since we're doing a more direct search, we need to specify a column.\n",
    "awk '$4 == \"99\" {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "rowB\t2\t7\t10\r\n",
      "file3\t3\t6\t20\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n"
     ]
    }
   ],
   "source": [
    "# Negate a search\n",
    "awk '$4 != \"99\" {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file4,99\r\n"
     ]
    }
   ],
   "source": [
    "## Print specific columns with a defined format\n",
    "awk '$4 == \"99\" {print $1\",\"$4}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file4,4,5\r\n"
     ]
    }
   ],
   "source": [
    "## Even use multiple conditions with && (AND)\n",
    "awk '$3 == \"5\" && $2 == \"4\" {print $1 \",\" $2 \",\" $3}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file4\t4\t5\t99\r\n"
     ]
    }
   ],
   "source": [
    "# || (OR)\n",
    "awk '$3 == \"5\" || $4 == \"3\" {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n"
     ]
    }
   ],
   "source": [
    "## Combine exact and patterns matching:\n",
    "# 'Print lines whose first column has an \"a\" or their 4th column is 99'\n",
    "awk '$1 ~ /a/ || $4 == \"99\" {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n"
     ]
    }
   ],
   "source": [
    "## Relational operators also work:\n",
    "awk '$2 > 3 {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n"
     ]
    }
   ],
   "source": [
    "#### Watch out, we can modify the values of a column if we're not careful:\n",
    "## This searches for lines whose second column is 1\n",
    "awk '$2 == 1 {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA 1 1 9\r\n",
      "rowB 1 7 10\r\n",
      "file3 1 6 20\r\n",
      "file4 1 5 99\r\n",
      "line_a 1 13 144\r\n",
      "line_b 1 16 177\r\n"
     ]
    }
   ],
   "source": [
    "## == is important. Using a single '=' changes  values on the second column for a 1\n",
    "awk '$2 = 1 {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n"
     ]
    }
   ],
   "source": [
    "#### The order of the operatios matter:\n",
    "# The instructions are followed as:\n",
    "## Either \n",
    "# a) Find an 'a' on the first column \n",
    "# OR\n",
    "# b) Find a 99 on the 4th column AND a value greater than 1 on the second  column.\n",
    "awk '$1 ~ /a/ || $4 == \"99\" && $2 > 1{print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n"
     ]
    }
   ],
   "source": [
    "## Either \n",
    "# a) Find an 'a' on the first column AND a value greater than 1 on the second column.\n",
    "# OR\n",
    "# b) Find a 99 on the 4th column \n",
    "\n",
    "awk '$1 ~ /a/ && $2 > 1 || $4 == \"99\" {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_a\t12\t13\t144\r\n"
     ]
    }
   ],
   "source": [
    "## We can use parentheses to group logical operations together.\n",
    "\n",
    "awk '$1 ~ /a/ && ( $2 > 1 || $4 == \"99\" ) {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Arithmetic Operations\n",
    "\n",
    "### ** + * - / **\n",
    "\n",
    "A powerful functionality of `awk` is to perform arithmetic operations as part of the parsing process. These can be combined with the pattern matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r\n",
      "2\r\n",
      "2\r\n",
      "2\r\n",
      "2\r\n",
      "2\r\n"
     ]
    }
   ],
   "source": [
    "## Let awk tell you how much 1 +1 is: \n",
    "awk '{ print 1 + 1 }' cols.txt\n",
    "\n",
    "## awk operates on a line-by-line basis, \n",
    "# we're instructing awk to, on each line, print the sum of 1 + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r\n"
     ]
    }
   ],
   "source": [
    "## Now print it only once:\n",
    "# We'll review the structures of an awk function later:\n",
    "awk ' END { print 1 + 1 }' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r\n"
     ]
    }
   ],
   "source": [
    "awk ' BEGIN { print 1 + 1 }' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r\n",
      "9\r\n",
      "9\r\n",
      "9\r\n",
      "25\r\n",
      "31\r\n"
     ]
    }
   ],
   "source": [
    "## We can sum values of columns:\n",
    "awk '{ print $2 + $3 }' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 2\r\n",
      "2 7 9\r\n",
      "3 6 9\r\n",
      "4 5 9\r\n",
      "12 13 25\r\n",
      "15 16 31\r\n"
     ]
    }
   ],
   "source": [
    "# Print the individual values per column and add a third column with the sum.\n",
    "awk '{ print $2, $3, $2 + $3 }' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_a\t12\t13\t144\r\n"
     ]
    }
   ],
   "source": [
    "## Use pattern matching and logic operations to sum values:\n",
    "awk '$1 ~ /a/ && ( $2 > 1 || $4 == \"99\" ) {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\r\n"
     ]
    }
   ],
   "source": [
    "## Sum columns 2 and 3:\n",
    "awk '$1 ~ /a/ && ( $2 > 1 || $4 == \"99\" ) {print $2 + $3}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative sums.\n",
    "\n",
    "Use of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9 1\r\n",
      "rowB\t2\t7\t10 2\r\n",
      "file3\t3\t6\t20 3\r\n",
      "file4\t4\t5\t99 4\r\n",
      "line_a\t12\t13\t144 5\r\n",
      "line_b\t15\t16\t177 6\r\n"
     ]
    }
   ],
   "source": [
    "## We can store values on variables for later use:\n",
    "# Create a variable to keep track of how many lines we've processed: \n",
    "awk 'BEGIN {counter=0} {counter += 1} {print $0,counter}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\t1\r\n",
      "rowB\t2\t7\t10\t2\r\n",
      "file3\t3\t6\t20\t3\r\n",
      "file4\t4\t5\t99\t4\r\n",
      "line_a\t12\t13\t144\t5\r\n",
      "line_b\t15\t16\t177\t6\r\n"
     ]
    }
   ],
   "source": [
    "# We can skip the initialization of the variable:\n",
    "awk '{counter += 1} {print $0 \"\\t\" counter}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "9\r\n"
     ]
    }
   ],
   "source": [
    "## Combine with pattern matching:\n",
    "# If column 2 is 1:\n",
    "## a) print the line.\n",
    "## b) aggregate the values of column 4\n",
    "## At the end of the run, print the cumulative sum of column 4 values for rows whose second column is 1.\n",
    "awk '$2 == \"1\" { print; sum += $4 } END { print sum }' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\t1\r\n",
      "\r\n",
      "\r\n",
      "9\r\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter, to keep track of the number of occurences, separate with a tab.\n",
    "# at the end of the run, skip a line, print the cumulative sum of column 4 for those lines.\n",
    "awk 'BEGIN {counter=0} $2 == \"1\" {counter+=1; print $0 \"\\t\" counter; sum += $4;  } END { print \"\\n\"; print sum }' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Means.\n",
    "\n",
    "Use of the counter to calculate means of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\t1\r\n",
      "\r\n",
      "\r\n",
      "9\r\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter, to keep track of the number of occurences, separate with a tab.\n",
    "# at the end of the run, skip a line, print the mean.\n",
    "awk 'BEGIN {counter=0} $2 == \"1\" {counter+=1; print $0 \"\\t\" counter; sum += $4;  } END { print \"\\n\"; print sum/counter }' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "rowB\t2\t7\t10\r\n",
      "file3\t3\t6\t20\r\n",
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n",
      "\r\n",
      "\r\n",
      "Means\t6.16667\t8\t76.5\r\n"
     ]
    }
   ],
   "source": [
    "## Calculate column means:\n",
    "awk 'BEGIN {counter=0} {print $0; tot2 +=$2;tot3 +=$3; tot4 +=$4; counter += 1 } END { print \"\\n\"; print \"Means\" \"\\t\" tot2/counter \"\\t\" tot3/counter \"\\t\" tot4/counter }' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More complex examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "rowB\t2\t7\t10\r\n",
      "file3\t3\t6\t20\r\n",
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n",
      "\r\n",
      "\t1\t1\t144\r\n"
     ]
    }
   ],
   "source": [
    "#### awk works by reading each line at a time.\n",
    "## The following code evaluates the instruction in the following way:\n",
    "# a) If the second column is 1, Store a cumulative sum in variable 'sum'.\n",
    "# b) If the value of the third column is less of equal than 2, do a cumulative sum.\n",
    "# c) If the rowname has an \"a\" sum the values on the 4th column\n",
    "# END the instructions\n",
    "# print the cumulative sums of column 2 if is 1 and column 3 if it's a 2.\n",
    "awk '{print $0} $2 == 1 { sum += $2 } $3 <= 2 {sum2 += $3} $1 ~ /a/ {sum3 += $4} END { print \"\\n\" \"\\t\" sum \"\\t\"  sum2 \"\\t\"  sum3 }' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### AWK programs basic structure\n",
    "\n",
    "As you might've noticed by now awk is line oriented. It will process each line at a time and thus we can do different processes on each line. \n",
    "\n",
    "The basic idea for an awk instruction is that an `instruction` is followed by an `{action}`:\n",
    "\n",
    "> ``awk '$2 > 1 {print $0}' cols.txt`` <br>\n",
    "> awk *__If__ the second column is larger than 1, __then__ {print the whole line}* \n",
    "\n",
    "Sometimes the instruction can be omitted (but not the action), in this case the default's action of awk is just to read every line.\n",
    "\n",
    "Multiple actions within a block can be separated by a semicolon (;)\n",
    "\n",
    "> ``awk 'instruction {action1;action2}'``\n",
    "\n",
    "\n",
    "`awk` also has two important block of instructions (but that can be also omitted): BEGIN and END.\n",
    "\n",
    "#### BEGIN\n",
    "\n",
    "It specifies an instruction and action to be performed BEFORE the start of the program (ie, before reading the lines). This can be useful to start variables or print something. \n",
    "\n",
    "The basic format for this block has to be specified using \"BEGIN\" then the action (in this case BEGIN is the instruction):\n",
    "\n",
    "> ``awk 'BEGIN {a=0} {a+=1; print a}' cols.txt`` <br>\n",
    "> *Start with a=0. For each line in cols.txt increase the value of a by 1 and print it.*\n",
    "\n",
    "#### END\n",
    "\n",
    "Specifies the actions AFTER the program has run (ie after the lines have been read). For example to avoid printing each time a line is read, we can print a single output by the end.\n",
    "\n",
    "> ``awk 'BEGIN {a=0} {a+=1} END {print a}' cols.txt`` <br>\n",
    "> *Start with a=0. For each line in cols.txt increase the value of a by 1. After reading each line print the final value of a.*\n",
    "\n",
    "In principle we can run awk with only one block of instructions (either BEGIN, END or the unnamed instruction that is executed on each line). \n",
    "\n",
    "\n",
    "> ``awk 'BEGIN {print \"Start of program\"}' cols.txt`` <br>\n",
    "> ``awk 'END {print \"End of program\"}' cols.txt`` <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOF (beginning of file)\r\n",
      "do something every line\r\n",
      "do something every line\r\n",
      "do something every line\r\n",
      "do something every line\r\n",
      "do something every line\r\n",
      "do something every line\r\n",
      "EOF (end of file)\r\n"
     ]
    }
   ],
   "source": [
    "# AWK\n",
    "awk 'BEGIN {print \"BOF (beginning of file)\"} {print \"do something every line\"} END {print \"EOF (end of file)\"}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of AWK Commands:\n",
    "\n",
    "\n",
    "* if    `awk '{if (NR%2==1) {print \"odd\"} else {print \"even\"}}' cols.txt`\n",
    "* while `awk 'BEGIN { i=1; while (i <= 10) {print \"The square of \", i, \" is \", i*i;i = i+1;}}' cols.txt`\n",
    "* for   `awk 'BEGIN { for (i=1; i <= 10; i++) {print \"The square of \", i, \" is \", i*i;}}' cols.txt`\n",
    "* length `awk '{print length($1)}' cols.txt`\n",
    "\n",
    "\n",
    "Others:\n",
    "\n",
    "* break\n",
    "* continue\n",
    "* print [ expression-list ] [ > expression ]\n",
    "* next \n",
    "* exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Passing variables to awk\n",
    "\n",
    "<br>\n",
    "# <center> ! </center>\n",
    "\n",
    "You can skip this section if you're going to use awk for one-liners outside of shell scripts or less complicated stuff.\n",
    "<br><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "When using awk inside shell scripts there's a special situation we should be aware of. Imagine you write a script to print out user defined columns using awk or just passing a variable to the program.\n",
    "\n",
    "In shell, variables are also defined by the *$* sign, thus it'd be logical to write the awk program passing the variable name as is, for example:\n",
    "\n",
    "> ``Column=1`` # variable indicating which column to print. <br>\n",
    "> ``echo $Column`` # print the variable <br>\n",
    "> `` awk '{print $$Column}' cols.txt `` # Call awk, pass the variable to print the column. <br>\n",
    "\n",
    "As you can see this will result in an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "Column=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk: illegal field $(), name \"Column\"\r\n",
      " input record number 1, file cols.txt\r\n",
      " source line number 1\r\n"
     ]
    }
   ],
   "source": [
    "# This will result in an error:\n",
    "awk '{print $$Column}' cols.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `awk` also uses **$** for variables we need to bypass the special character by toggling off the interpreter at the variable name, so that it's recognized as such. We use quotes to switch it off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\r\n",
      "rowB\r\n",
      "file3\r\n",
      "file4\r\n",
      "line_a\r\n",
      "line_b\r\n"
     ]
    }
   ],
   "source": [
    "awk '{print $'$Column'}' cols.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation: default variables\n",
    "\n",
    "Set up default variables when writing shell scripts. This way if the input is empty or not set, it will take on a default value.\n",
    "\n",
    "The format is as follows: ``${variable:-defaultvalue}``\n",
    "\n",
    "For example:\n",
    "\n",
    ">``column=2 #Choose any value `` <br>\n",
    ">``column=${column:-1} #Set column as the same variable. If empty, it will take on the default value of 1.`` <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "1\r\n"
     ]
    }
   ],
   "source": [
    "## Example with an empty input. If no input is given, the value is overriden by the default.\n",
    "column=\n",
    "echo $column\n",
    "column=${column:-1}\n",
    "echo $column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r\n",
      "2\r\n"
     ]
    }
   ],
   "source": [
    "## Example with a valid input. The value chosen is NOT overwritten.\n",
    "column=2\n",
    "echo $column\n",
    "column=${column:-1}\n",
    "echo $column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to AWK\n",
    "\n",
    "<br>\n",
    "\n",
    "### Positional Variables\n",
    "\n",
    "The variables we've used so far are user-defined, that is, we decide the value that the variable will take. \n",
    "\n",
    "awk's positional variables are functions called by the dollar sign:\n",
    "\n",
    "In the following code, `a` is a user defined variable, we assign the value 0 and it will increase by one on each line. The positional variable `$1` points to the first column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\r\n",
      "rowB\t2\r\n",
      "file3\t3\r\n",
      "file4\t4\r\n",
      "line_a\t5\r\n",
      "line_b\t6\r\n"
     ]
    }
   ],
   "source": [
    "awk 'BEGIN {a=0} {a+=1; print $1 \"\\t\" a}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional variables can be modified:\n",
    "\n",
    "In the following line we rename the rows to their position by chaning the value of $1 for a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 9\r\n",
      "2 2 7 10\r\n",
      "3 3 6 20\r\n",
      "4 4 5 99\r\n",
      "5 12 13 144\r\n",
      "6 15 16 177\r\n"
     ]
    }
   ],
   "source": [
    "awk 'BEGIN {a=0} {a+=1; print $1=a,$2,$3,$4}' cols.txt # The output can be redirected to a new text file appending `> newfile.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Summary:\n",
    "\n",
    "There are 8 positional variables in awk. These are not user-defined but built in into awk and they're called with `$`.\n",
    "\n",
    "* {number}. Indicates a specific column. If 0, then prints the whole line.\n",
    "* `NF` (Number of fields). Indicates the number of fields (columns) in the line.\n",
    "* `NR` (Number of records). Indicates the number of records (lines) in the line.\n",
    "* `FS` (Field separator). Indicates which character to use as **column** separator when reading the file.\n",
    "* `OFS` (Output field separator). Indicates which character to use as **column** separator when printing the output.\n",
    "* `RS` (Record separator). Indicates which character to use as **line** separator when reading the file.\n",
    "* `ORS` (Output record separator). Indicates which character to use as **line** separator when printing the output.\n",
    "* `FILENAME`. Name of the file being read.\n",
    "\n",
    "Using these variables along with conditions (if,else) can have interesting results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field Separator\n",
    "\n",
    "By default awk parses lines and separates them by whitespaces. If the file we're parsing has separators other than this (ie a comma separated file) we can change the value using the `FS` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "rowB\t2\t7\t10\r\n",
      "file3\t3\t6\t20\r\n",
      "---\r\n",
      "rowA,1,1,9\r\n",
      "rowB,2,7,10\r\n",
      "file3,3,6,20\r\n"
     ]
    }
   ],
   "source": [
    "## I converted the counts.txt to a csv file with vim:\n",
    "# Used > :%s/\\s\\+/,/g < to convert\n",
    "head -n 3 cols.txt\n",
    "echo \"---\"\n",
    "head -n 3 cols.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   \r\n",
      "2   \r\n",
      "3   \r\n",
      "4   \r\n",
      "5   \r\n",
      "6   \r\n"
     ]
    }
   ],
   "source": [
    "## The default awk won't be able to read it:\n",
    "awk 'BEGIN {a=0} {a+=1; print $1=a,$2,$3,$4}' cols.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 9\r\n",
      "2 2 7 10\r\n",
      "3 3 6 20\r\n",
      "4 4 5 99\r\n",
      "5 12 13 144\r\n",
      "6 15 16 177\r\n"
     ]
    }
   ],
   "source": [
    "## But we can switch the field separator to a \",\"\n",
    "awk -F, 'BEGIN {a=0} {a+=1; print $1=a,$2,$3,$4}' cols.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 9\r\n",
      "2 2 7 10\r\n",
      "3 3 6 20\r\n",
      "4 4 5 99\r\n",
      "5 12 13 144\r\n",
      "6 15 16 177\r\n"
     ]
    }
   ],
   "source": [
    "## Or set the FS variable\n",
    "awk 'BEGIN {a=0;FS=\",\"} {a+=1; print $1=a,$2,$3,$4}' cols.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "7\r\n",
      "6\r\n",
      "\r\n",
      "13\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Check if the Field Separator matches a character.\n",
    "awk ' { if ($0 ~ /\":\"/) {FS=\":\";} else {FS=\",\";$0=$0} print $3 }' fubar.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA:1:1:9\r\n",
      "rowB,2,7,10\r\n",
      "file3,3,6,20\r\n",
      "file4:4:5:99\r\n",
      "line_a,12,13,144\r\n",
      "line_b:15:16:177\r\n"
     ]
    }
   ],
   "source": [
    "# The above script prints column 3 from rows separated with a comma\n",
    "cat fubar.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Output Field Separator\n",
    "\n",
    "When printing outputs there is a difference between printing \n",
    "\n",
    "> ``awk '{print $1 $2}' cols.txt``\n",
    "\n",
    "And printing \n",
    "\n",
    "> ``awk '{print $1,$2}' cols.txt``\n",
    "\n",
    "Using a space will concatenate the output into a single field, using the comma will print two fields with the Output Field Separator (OFS) between them. \n",
    "\n",
    "By default the OFS is a space but can be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\r\n",
      "rowB\t2\r\n",
      "file3\t3\r\n",
      "file4\t4\r\n",
      "line_a\t12\r\n",
      "line_b\t15\r\n",
      "---\r\n",
      "rowA,1\r\n",
      "rowB,2\r\n",
      "file3,3\r\n",
      "file4,4\r\n",
      "line_a,12\r\n",
      "line_b,15\r\n",
      "---\r\n",
      "rowA:1\r\n",
      "rowB:2\r\n",
      "file3:3\r\n",
      "file4:4\r\n",
      "line_a:12\r\n",
      "line_b:15\r\n"
     ]
    }
   ],
   "source": [
    "awk 'BEGIN {OFS=\"\\t\"} {print $1,$2}' cols.txt\n",
    "echo \"---\"\n",
    "awk 'BEGIN {OFS=\",\"} {print $1,$2}' cols.txt\n",
    "echo \"---\"\n",
    "awk 'BEGIN {OFS=\":\"} {print $1,$2}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Fields\n",
    "\n",
    "The `NF` variable tells us the number of fields (columns) that a file has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r\n"
     ]
    }
   ],
   "source": [
    "awk 'END  {print NF}' cols.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r\n",
      "10\r\n",
      "20\r\n",
      "99\r\n",
      "144\r\n",
      "177\r\n"
     ]
    }
   ],
   "source": [
    "## We can take the advantage of the value of NF and print the \\ \n",
    "# last column of a file using the NF as a call to the field variable:\n",
    "awk '{print $NF}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ! </center>\n",
    "\n",
    "AWK has a limit of 99 fields in a single line ($1 to $99). Other programming languages (like Perl) don't have such limits to handle multiple fields/columns.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Records\n",
    "\n",
    "The `NR` variable tells us the number of records (lines) in a file.\n",
    "\n",
    "This is useful if we were reading a file with a header (column names) and wish to skip the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 rowB\t2\t7\t10\r\n",
      "3 file3\t3\t6\t20\r\n",
      "4 file4\t4\t5\t99\r\n",
      "5 line_a\t12\t13\t144\r\n",
      "6 line_b\t15\t16\t177\r\n"
     ]
    }
   ],
   "source": [
    "## We can skip n lines with a condition for the NR value:\n",
    "awk '{ if (NR > 1) {print NR, $0;}}' cols.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 rowB\t2\t7\t10\r\n",
      "3 file3\t3\t6\t20\r\n",
      "4 file4\t4\t5\t99\r\n",
      "5 line_a\t12\t13\t144\r\n",
      "6 line_b\t15\t16\t177\r\n"
     ]
    }
   ],
   "source": [
    "# We get the same effect just by indicating the condition (without the If/else statement)\n",
    "awk 'NR>1 {print NR, $0}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Separator\n",
    "\n",
    "AWK reads one line at a time and separates each line into columns (fields).\n",
    "\n",
    "The `RS` variable indicates the character used to separate records (lines).\n",
    "\n",
    "By default the end of line (EOL) is \"\\n\". If the document has any other type of end-of-line character we specify it with RS in the BEGIN block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rowA,1,1,9 rowB,2,7,10 file3,3,6,20 file4,4,5,99\r\n",
      "\r\n",
      "\r\n",
      "Rows: 1 Columns: 6\r\n"
     ]
    }
   ],
   "source": [
    "## Define the end of a line as a white space. Print the record number and then the columns.\n",
    "# By redefining the lines as whitespace, the field separator is now the end of the line (\"\\n\") and thus \\\n",
    "# the file is a 1x4 table: 1 column and each line becomes a column.\n",
    "awk 'BEGIN {RS=\" \"} {print NR,$1,$2,$3,$4} END {print\"\\n\";print \"Rows:\",NR,\"Columns:\",NF}' cols.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rowA,1,1,9   \r\n",
      "2 rowB,2,7,10   \r\n",
      "3 file3,3,6,20   \r\n",
      "4 file4,4,5,99   \r\n",
      "5 line_a,12,13,144   \r\n",
      "6 line_b,15,16,177   \r\n",
      "\r\n",
      "\r\n",
      "Rows: 6 Columns: 1\r\n"
     ]
    }
   ],
   "source": [
    "awk '{print NR,$1,$2,$3,$4} END {print\"\\n\";print \"Rows:\",NR,\"Columns:\",NF}' cols.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rowA\r\n",
      "2 1\r\n",
      "3 1\r\n",
      "4 9\r\n",
      "rowB\r\n",
      "5 2\r\n",
      "6 7\r\n",
      "7 10\r\n",
      "file3\r\n",
      "8 3\r\n",
      "9 6\r\n",
      "10 20\r\n",
      "file4\r\n",
      "11 4\r\n",
      "12 5\r\n",
      "13 99\r\n",
      "line_a\r\n",
      "14 12\r\n",
      "15 13\r\n",
      "16 144\r\n",
      "line_b\r\n",
      "17 15\r\n",
      "18 16\r\n",
      "19 177\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Rows: 19 Columns: 1\r\n"
     ]
    }
   ],
   "source": [
    "# If we specify the field separator as the record separator we'll read one word per line\n",
    "awk 'BEGIN {RS=\"\\t\"} {print NR,$0} END {print\"\\n\";print \"Rows:\",NR,\"Columns:\",NF}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Output Record Separator\n",
    "\n",
    "The `ORS` variable indicates the character used to separate records (lines) __in the output__.\n",
    "\n",
    "By default the end of line (EOL) is \"\\n\". If we want the document to have any other type of end-of-line character we specify it with RS in the BEGIN block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9;rowB\t2\t7\t10;file3\t3\t6\t20;file4\t4\t5\t99;line_a\t12\t13\t144;line_b\t15\t16\t177;"
     ]
    }
   ],
   "source": [
    "awk 'BEGIN {ORS=\";\"} {print $0}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Filename\n",
    "\n",
    "The `FILENAME` variable indicates the name of the file being read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowA\t1\t1\t9\r\n",
      "rowB\t2\t7\t10\r\n",
      "file3\t3\t6\t20\r\n",
      "file4\t4\t5\t99\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n",
      "\r\n",
      "\r\n",
      "Rows: 6 Columns: 4 File: cols.txt\r\n"
     ]
    }
   ],
   "source": [
    "awk '{print $0} END {print\"\\n\";print \"Rows:\",NR,\"Columns:\",NF, \"File:\", FILENAME}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associattive Arrays\n",
    "\n",
    "Most programming languages would count occurences of an event in two arrays: one for the name and the other for the number, and the index would link them together (ie, a table is with one column being the name, the other the number)\n",
    "\n",
    "`AWK` overcomes this issue using associative arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Count the number of files that a user has.\n",
    "\n",
    "## Bad awk\n",
    "\n",
    "ls -l . | \\    \n",
    "  awk 'BEGIN {number_of_users=0;} { \\\n",
    "          if (NF>7) { user=0; for (i=1; i<=number_of_users; i++) {\\\n",
    "         if (username[i] == $3) {user=i;}} \\\n",
    "          if (user == 0) {username[++number_of_users]=$3;user=number_of_users;}count[user]++;} \\\n",
    "          }\\\n",
    "        END {for (i=1; i<=number_of_users; i++) {print count[i], username[i]}}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quick and dirty solution\n",
    "ls -l | awk '{print $3}' | sort | uniq -c | sort -nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Good awk\n",
    "ls -l | awk '{username[$3]++;} END { for (i in username) {print username[i], i; }}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 jrm\r\n"
     ]
    }
   ],
   "source": [
    "## Better awk programming\n",
    "\n",
    "ls -l | awk 'BEGIN {username[\"\"]=0;}{username[$3]++;}END {for (i in username) {if (i != \"\") {print username[i], i;}}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All arrays in AWK are associative arrays. \n",
    "\n",
    "When adding entries and counts in the arrays the counts are incremented by invoking:\n",
    "\n",
    "`entry[variable]++;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying awk to real biological data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a SAM file with information of sequence reads aligned to the Arabidopsis genome. The format of this type of data is constant, so we can apply awk commands over these files with ease and these scripts can work for more than one SAM file.\n",
    "\n",
    "You can read more about the format here: https://en.wikipedia.org/wiki/SAM_(file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First let's take a look at how the file looks\n",
    "head -n 3 bowtie2_genome.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file containts 5346701 entries (alignments or lines) : `wc -l bowtie2_genome.sam`\n",
    "\n",
    "`awk 'END {print NR}' bowtie2_genome.sam #Prints the NR of the last line (index) which is effectively the number of lines.`\n",
    "\n",
    "\n",
    "#### RNAME \n",
    "\n",
    "Let's count how many reads are mapped to the different chromosomes. To do this we use the third column of the SAM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410685 Chr1\r\n",
      "1094098 Chr5\r\n",
      "1058436 Chr3\r\n",
      "886535 Chr4\r\n",
      "864493 Chr2\r\n",
      "22383 mitochondria\r\n",
      "10071 chloroplast\r\n",
      "119\r\n"
     ]
    }
   ],
   "source": [
    "##One way to do it is to pipe different commands: `cut` the file for column 3 (the field containing the )      \n",
    "\n",
    "SECONDS=0; head -n 5346701 bowtie2_genome.sam | cut -f 3 | sort | uniq -c | sort -nr; echo $SECONDS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10071 chloroplast\r\n",
      "1410685 Chr1\r\n",
      "864493 Chr2\r\n",
      "1058436 Chr3\r\n",
      "886535 Chr4\r\n",
      "1094098 Chr5\r\n",
      "22383 mitochondria\r\n",
      "59\r\n"
     ]
    }
   ],
   "source": [
    "## Using awk and associtive arrays we get the same result but in a much faster time. \n",
    "SECONDS=0; head -n 5346701 bowtie2_genome.sam | \\\n",
    "    awk '{chromosome[$3]++;} END { for (i in chromosome) {print chromosome[i], i; } }';  \\\n",
    "echo $SECONDS;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using awk read and processed the __5346701 lines in ~59 seconds__, while stitching (with pipe: \"|\") the columns to sort and unique takes about twice as much (~119 seconds). \n",
    "\n",
    "#### MAPQ\n",
    "\n",
    "The 5th column of the SAM format gives us the qualities of the mapping. The quality is measured as the −10 log10 Pr{mapping position is wrong}.\n",
    "\n",
    "See more about qualities here: http://www.acgt.me/blog/2014/12/16/understanding-mapq-scores-in-sam-files-does-37-42\n",
    "\n",
    "Values for 255 indicate the mapping quality is not available.\n",
    "\n",
    "Using awk we can:\n",
    "\n",
    "\n",
    "* filter out reads with low quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J00113:234:HGCCMBBXX:6:1101:5690:1297\t16\tChr1\t2338748\t32\t42M\t*\t0\t0\tAATACAAAGCTGGGAAAAGTCAAAGCTTAAGAGAGTTGATAC\tJJJJJFJA7FFFFFJJJJFJFJFFFJJFFJAFFJJJJFJFFJ\tAS:i:84\tXS:i:74\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:5690:1297\t272\tChr5\t22971914\t32\t1S20M1D21M\t*\t0\t0\tAATACAAAGCTGGGAAAAGTCAAAGCTTAAGAGAGTTGATAC\tJJJJJFJA7FFFFFJJJJFJFJFFFJJFFJAFFJJJJFJFFJ\tAS:i:74\tXS:i:74\tXN:i:0\tXM:i:0\tXO:i:1\tXG:i:1\tNM:i:1\tMD:Z:20^A21\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:27630:1297\t0\tChr4\t7439507\t31\t42M\t*\t0\t0\tCGTAAGTTGAATACCTATGACATACCTATGAAACAAACGAAT\tAFJJJJ<J7<<FJAA<FF-F--<F7<-F77F-FAFJJAFJ<A\tAS:i:84\tXS:i:78\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:27630:1297\t256\tChr4\t7434582\t31\t42M\t*\t0\t0\tCGTAAGTTGAATACCTATGACATACCTATGAAACAAACGAAT\tAFJJJJ<J7<<FJAA<FF-F--<F7<-F77F-FAFJJAFJ<A\tAS:i:78\tXS:i:78\tXN:i:0\tXM:i:1\tXO:i:0\tXG:i:0\tNM:i:1\tMD:Z:29A12\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:9171:1314\t0\tChr3\t5580741\t38\t42M\t*\t0\t0\tCATATGAGGTCTCTTCATGCCTCTGGTGAATGGTGATCTTTG\tJJJJJJJJJJFJFJJAFFJJAA<JJJJFJJJJJJJJJFAAJJ\tAS:i:84\tXS:i:50\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:9171:1314\t256\tChr3\t5583023\t38\t4S25M13S\t*\t0\t0\tCATATGAGGTCTCTTCATGCCTCTGGTGAATGGTGATCTTTG\tJJJJJJJJJJFJFJJAFFJJAA<JJJJFJJJJJJJJJFAAJJ\tAS:i:50\tXS:i:50\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:25\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:16965:1314\t0\tChr4\t11754532\t33\t42M\t*\t0\t0\tTTCTGTTTGTTTTGCGTTGTCAAGTATCAAATAAAGTTGGAG\tJJJJJJFJJJJJJJJJAFJJFJJJJJJFJJJJJJJJAJFJJJ\tAS:i:84\tXS:i:68\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:16965:1314\t256\tChr4\t11752942\t33\t42M\t*\t0\t0\tTTCTGTTTGTTTTGCGTTGTCAAGTATCAAATAAAGTTGGAG\tJJJJJJFJJJJJJJJJAFJJFJJJJJJFJJJJJJJJAJFJJJ\tAS:i:68\tXS:i:68\tXN:i:0\tXM:i:2\tXO:i:0\tXG:i:0\tNM:i:2\tMD:Z:25C2C13\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:18416:1332\t0\tChr3\t20501483\t33\t42M\t*\t0\t0\tTGCTTTGGATGTGGCTAACAAAATCGGGATCATCTAATCTGA\tJ<JA<AJ-F-7<7FJFJJJJJJJJJJJJJF<FFFJFJJJJJJ\tAS:i:84\tXS:i:69\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:18416:1332\t256\tChr3\t20503895\t33\t42M\t*\t0\t0\tTGCTTTGGATGTGGCTAACAAAATCGGGATCATCTAATCTGA\tJ<JA<AJ-F-7<7FJFJJJJJJJJJJJJJF<FFFJFJJJJJJ\tAS:i:69\tXS:i:69\tXN:i:0\tXM:i:2\tXO:i:0\tXG:i:0\tNM:i:2\tMD:Z:8T29T3\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:11241:1384\t0\tChr2\t7509731\t38\t42M\t*\t0\t0\tGTTTGATTATGTTAAGATTGGAACTGTTTGATTATGTTAAGA\tAAJJJJJJJJJJJJJJJJJJJJJJFJFJFFJJJJJJJJJJJJ\tAS:i:84\tXS:i:48\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:11241:1384\t256\tChr2\t7509756\t38\t24M18S\t*\t0\t0\tGTTTGATTATGTTAAGATTGGAACTGTTTGATTATGTTAAGA\tAAJJJJJJJJJJJJJJJJJJJJJJFJFJFFJJJJJJJJJJJJ\tAS:i:48\tXS:i:48\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:24\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:13738:1384\t0\tChr3\t5568311\t32\t42M\t*\t0\t0\tACGGGATTGACTCTGCCTAATTAAGGCAGATTTGGTGATCAT\tJJJFJJJFJJFJFJFAFJJFFJJFFJF7AJFFJFJJJFJ7AF\tAS:i:84\tXS:i:70\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:13738:1384\t256\tChr3\t5574340\t32\t39M3S\t*\t0\t0\tACGGGATTGACTCTGCCTAATTAAGGCAGATTTGGTGATCAT\tJJJFJJJFJJFJFJFAFJJFFJJFFJF7AJFFJFJJJFJ7AF\tAS:i:70\tXS:i:70\tXN:i:0\tXM:i:1\tXO:i:0\tXG:i:0\tNM:i:1\tMD:Z:4A34\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:13474:1420\t16\tChr3\t15801085\t31\t42M\t*\t0\t0\tAGGACCGTACTTCTTCGGATGAGAGTTCCATACATTAGAGTG\tF<7-JFFJFFJJJJ7AFF-AA<FJJJJJ<JJF<<FFAFFJJA\tAS:i:84\tXS:i:76\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:13474:1420\t272\tChr3\t15779188\t31\t42M\t*\t0\t0\tAGGACCGTACTTCTTCGGATGAGAGTTCCATACATTAGAGTG\tF<7-JFFJFFJJJJ7AFF-AA<FJJJJJ<JJF<<FFAFFJJA\tAS:i:76\tXS:i:76\tXN:i:0\tXM:i:1\tXO:i:0\tXG:i:0\tNM:i:1\tMD:Z:30G11\tYT:Z:UU\r\n",
      "J00113:234:HGCCMBBXX:6:1101:8186:1437\t0\tChr5\t16716357\t34\t42M\t*\t0\t0\tGTGAGGAAGACGAGATCCGTGTGCTACAAGGTATGATGGATT\tJAFJJJJJJJFJFAAJJJFJJJJ<JJ<FFF<AFJJJFJJ<J7\tAS:i:84\tXS:i:62\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:42\tYT:Z:UU\r\n",
      "0\r\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "#SECONDS=0; head -n 5346701 bowtie2_genome.sam | \\\n",
    "SECONDS=0; head -n 100 bowtie2_genome.sam |\\\n",
    "    awk '{ if ($5 != 255) {print $0} else {qual[$5]++} }  END { for (i in chromosome) {print i, chromosome[i]; } } ';\\\n",
    "    echo $SECONDS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 10\r\n"
     ]
    }
   ],
   "source": [
    "## Only keep lines with an available MAPQ. Count \n",
    "## If mapq is 255 \n",
    "head -n 10 bowtie2_genome.sam | \\\n",
    "awk '{if ($5 == 255) {qual[$5]++} else {print $0}} END { for (i in qual) {print i, qual[i]}}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 49377\r\n",
      "31 179607\r\n",
      "32 110361\r\n",
      "33 121616\r\n",
      "34 116134\r\n",
      "35 87025\r\n",
      "37 61411\r\n",
      "38 66742\r\n",
      "39 97631\r\n",
      "255 4456797\r\n",
      "61\r\n"
     ]
    }
   ],
   "source": [
    "## Distribution of qualities\n",
    "SECONDS=0; head -n 5346701 bowtie2_genome.sam | \\\n",
    "#SECONDS=0; head -n 100 bowtie2_genome.sam | \\\n",
    "    awk '{chromosome[$5]++;} END { for (i in chromosome) {print i, chromosome[i]; } }';  \\\n",
    "echo $SECONDS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odd\r\n",
      "even\r\n",
      "odd\r\n",
      "even\r\n",
      "odd\r\n",
      "even\r\n"
     ]
    }
   ],
   "source": [
    "awk '{if (NR%2==1) {print \"odd\"} else {print \"even\"}}' cols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redirection\n",
    "\n",
    "For example we want to redirect reads with no quality mapping to one file and reads with a quality mapping to another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This oneliner filters a SAM file by MAPQ values:\n",
    "\n",
    "# Creates a file for reads without available quality.\n",
    "# Creates a file for reads with quality.\n",
    "## Algorithm:\n",
    "# Gets the name file, removes the suffix (.sam)\n",
    "# Creates a variable for the file names of the output.\n",
    "# For every line checks if the quality is 255 or not.\n",
    "# If so, sends the reads to one line (low), if not, sends the reads to another file (pass)\n",
    "# prints a summary of how many reads have low quality.\n",
    "\n",
    "awk 'BEGIN{file=ARGV[1]; gsub(/.sam/,\"\", file); pass=file\"_okMAPQ.sam\"; low=file\"_bad.sam\"}\\\n",
    "     {if ($5 == 255) {print $0 > low;qual[$5]++} else {print $0>pass}}\\\n",
    "     END { for (i in qual) {print i, qual[i]}}' SAMtest200.sam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wc -l SAMtest200_bad.txt # Same as the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## We can add some cool features to this script. \n",
    "\n",
    "# We can create a file with the distribution of qualities\n",
    "awk 'BEGIN{file=ARGV[1]; gsub(/.sam/,\"\", file); \\\n",
    "            pass=file\"_okMAPQ.sam\"; low=file\"_bad.sam\";distr=file\"_MAPQdistribution.txt\";} \\\n",
    "    {if ($5 == 255) {print $0 > low;qual[$5]++} else {print $0>pass;qual[$5]++}} \\\n",
    "    END { for (i in qual) {print i, qual[i] > distr}}' SAMtest200.sam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## Add a filter for low quality reads (including reads with MAPQ=255)\n",
    "\n",
    "awk 'BEGIN{file=ARGV[1]; gsub(/.sam/,\"\", file); \\\n",
    "            pass=file\"_okMAPQ.sam\"; low=file\"_bad.sam\";distr=file\"_MAPQdistribution.txt\";} \\\n",
    "    {if ($5 == 255 || $5 < 37) {print $0 > low;qual[$5]++} else {print $0>pass;qual[$5]++}} \\\n",
    "    END { for (i in qual) {print i, qual[i] > distr}}' SAMtest200.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## Add a filter for low quality reads (MAPQ < 37) (including reads with MAPQ=255) AND \n",
    "# reads from non genomic locations (chloroplast or mitochondria)\n",
    "\n",
    "awk 'BEGIN{file=ARGV[1]; gsub(/.sam/,\"\", file); \\\n",
    "            pass=file\"_okMAPQ.sam\"; low=file\"_bad.sam\";distr=file\"_MAPQdistribution.txt\";} \\\n",
    "    {if ($5 == 255 || $5 < 37 || $3 ~ /chl|mit/ ) {print $0 > low;qual[$5]++} else {print $0>pass;qual[$5]++}} \\\n",
    "    END { for (i in qual) {print i, qual[i] > distr}}' SAMtest200.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Processing fasta files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     109\r\n"
     ]
    }
   ],
   "source": [
    "grep \">\" promoters.fa | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\r\n"
     ]
    }
   ],
   "source": [
    "# Count number of entries in the fasta file\n",
    "#awk ' {if ($1 ~ />/) {print $0} else {} } ' promoters.fa\n",
    "awk ' BEGIN {c=0} {if ($1 ~ />/) {c+=1;} } END {print c} ' promoters.fa \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert a FASTA file to uppercase\n",
    "########\n",
    "awk 'BEGIN{c=0; file=ARGV[1]; gsub(/.fa/,\"\", file); toFile=file\"_upper.fa\";}\\\n",
    "            {if ($1 ~ />/) {c+=1;print $0;} else {print toupper($0)} } END {print c, toFile} ' promoters.fa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 promoters_upper.fa\r\n"
     ]
    }
   ],
   "source": [
    "## Save results to file\n",
    "awk 'BEGIN{c=0; file=ARGV[1]; gsub(/.fa|.fasta/,\"\", file); toFile=file\"_upper.fa\";}\\\n",
    "      {if ($1 ~ />/) {c+=1;print $0 > toFile;} else {print toupper($0)> toFile} } END {print c, toFile} ' promoters.fa \n",
    "########            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Searching for patterns in fasta files.\n",
    "\n",
    "We can use conditions to split a fasta file based in patterns (filtering by either the header names or the sequences).\n",
    "\n",
    "More on regular expressions: https://www.cheatography.com/davechild/cheat-sheets/regular-expressions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Genes with match: 10 \r\n",
      " Genes with no match: 99\r\n"
     ]
    }
   ],
   "source": [
    "## Filter a FASTA file: header names with pattern go to one file, genes with no match go to another file.\n",
    "########\n",
    "awk 'BEGIN{m=0;nom=0; file=ARGV[1]; gsub(/.fa|.fasta/,\"\", file); passFile=file\"_ok.fa\"; noFile=file\"_no.fa\"}\\\n",
    "      {if ($1 ~ />/) { tmp=$0;}\\\n",
    "      else { if (tmp ~ /Gen02/) {m+=1; print tmp,RS,toupper($0) > passFile}\\\n",
    "                               else {nom+=1; print tmp,RS,toupper($0) > noFile} }}\\\n",
    "                               END {print \" Genes with match:\",m,RS,\"Genes with no match:\",nom} ' promoters.fa \n",
    "########            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Genes with match: 20 \r\n",
      " Genes with no match: 89\r\n"
     ]
    }
   ],
   "source": [
    "## Filter a FASTA file: sequences with pattern go to one file, sequences with no match go to another file.\n",
    "########\n",
    "awk 'BEGIN{m=0;nom=0; file=ARGV[1]; gsub(/.fa|.fasta/,\"\", file); passFile=file\"_ok.fa\"; noFile=file\"_no.fa\"}\\\n",
    "      {if ($1 ~ />/) { tmp=$0;}\\\n",
    "      else { if (toupper($0 )~ /CCC.{1,4}GGG/) {m+=1; print tmp,RS,toupper($0) > passFile}\\\n",
    "                               else {nom+=1; print tmp,RS,toupper($0) > noFile} }}\\\n",
    "                               END {print \" Genes with match:\",m,RS,\"Genes with no match:\",nom} ' promoters.fa \n",
    "# The pattern using grep would be \"CCC.\\{1,4\\}GGG\" with slashes between the intervals:\n",
    "#grep -i \"CCC.\\{1,4\\}GGG\" promoters.fa  -B 1 | grep \">\" | wc -l\n",
    "########            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### FASTQ processing\n",
    "\n",
    "Fastq files have a special format. They're composed of 4 lines:\n",
    "\n",
    "* header, starts with an @.\n",
    "* read sequence. Nucleotides (including N).\n",
    "* quality separator, starts with a +. May or may not have the same information as the header (except for the @).\n",
    "* quality (in phred scores).\n",
    "\n",
    "\n",
    "We can ask the value of the module of the line number divided by 4:\n",
    "\n",
    "* If $n$=1: header\n",
    "* If $n$=2: read\n",
    "* If $n$=3: + separator\n",
    "* If $n$=0: quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SRR1463325.1 HS2:447:C2DFYACXX:5:1101:1336:2178 length=59\r\n",
      "@SRR1463325.2 HS2:447:C2DFYACXX:5:1101:1364:2181 length=59\r\n",
      "200000\r\n"
     ]
    }
   ],
   "source": [
    "## Read the header\n",
    "awk ' BEGIN {c=0} {if ($1 ~ /@/) {c+=1; if (NR < 8) {print $0};} } END {print c} ' testSeq.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1\t@SRR1463325.1 HS2:447:C2DFYACXX:5:1101:1336:2178 length=59\r\n",
      "2\t2\tATGTTAGTAACCGAACCTTCTTCAAAAAGGGCTAAGGGATAAGCTACATACGCAATAAA\r\n",
      "3\t3\t+SRR1463325.1 HS2:447:C2DFYACXX:5:1101:1336:2178 length=59\r\n",
      "4\t0\tBBBFFFBFFFF0FF0FFBBB0BFFFFIFBF0BBF<B<BF<BB<FFIFFBBBBF######\r\n",
      "5\t1\t@SRR1463325.2 HS2:447:C2DFYACXX:5:1101:1364:2181 length=59\r\n",
      "6\t2\tACGCATTTATTAGATAAAAGGTCGACGCGGGCTCTGCCCGTTGCTCTGATGATTCATGA\r\n",
      "7\t3\t+SRR1463325.2 HS2:447:C2DFYACXX:5:1101:1364:2181 length=59\r\n",
      "8\t0\tBBBFFFFFFFFFFFFFIIIFIFIIF'B7FFFBBBFF'7BFBFBFBBFBB<B7<7'0<B<\r\n",
      "9\t1\t@SRR1463325.3 HS2:447:C2DFYACXX:5:1101:1499:2208 length=59\r\n",
      "10\t2\tAGGACCTCTTTAGTATTTTTGTTGATGACCAAAGCACCAGCACCTACAACATGAGAAGC\r\n",
      "11\t3\t+SRR1463325.3 HS2:447:C2DFYACXX:5:1101:1499:2208 length=59\r\n",
      "12\t0\tBBBFFFFFFFFFFFFFIIIIIIIIIIIIIIIIIIIFIIIFIIIFFIIIIIIIIFFIIIB\r\n",
      "13\t1\t@SRR1463325.4 HS2:447:C2DFYACXX:5:1101:1648:2157 length=59\r\n",
      "14\t2\tNTGTAGAATCTATGTTGAATCACCATTTAGCAGGGCTACTAGGACTTGGGTCCCTTTCT\r\n",
      "15\t3\t+SRR1463325.4 HS2:447:C2DFYACXX:5:1101:1648:2157 length=59\r\n",
      "16\t0\t#0<BFFFFFFFFFIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIFFIIIFFII\r\n",
      "17\t1\t@SRR1463325.5 HS2:447:C2DFYACXX:5:1101:1776:2228 length=59\r\n",
      "18\t2\tAGCCTCTTTCCGATCTTCTCAACTCCAAGGCTCTCAACGAACTTCCTCACTTCATCATC\r\n",
      "19\t3\t+SRR1463325.5 HS2:447:C2DFYACXX:5:1101:1776:2228 length=59\r\n",
      "20\t0\t<<0<BFBFBFB0BF<FFFBFFFB<B0BB<<FBFFBFBFBF<FBBFFFFBB<707<B<<7\r\n",
      "21\t1\t@SRR1463325.6 HS2:447:C2DFYACXX:5:1101:1956:2235 length=59\r\n",
      "22\t2\tAGAGTCAATAATTTTATATGAGGAACTACTGAACTCAATCACTTGCTGCCGTTACTCTT\r\n",
      "23\t3\t+SRR1463325.6 HS2:447:C2DFYACXX:5:1101:1956:2235 length=59\r\n",
      "24\t0\t<B<BBFFBFFF<BFFIIFFFFFFFFFFFFIIFIIIIFIF<FFFIFFFFFIIFF0BBF<F\r\n",
      "25\t1\t@SRR1463325.7 HS2:447:C2DFYACXX:5:1101:2058:2150 length=59\r\n",
      "26\t2\tNTGTTTGAGGGGGAGGTCATAAGCGTCTATACCGTAAAATAGATTTTCGACGAAATGCA\r\n",
      "27\t3\t+SRR1463325.7 HS2:447:C2DFYACXX:5:1101:2058:2150 length=59\r\n",
      "28\t0\t#0<BFFFFFFFFFFFIFFFIIIIIIFFIFIIIIIFIIFFFFIIIIIIIFFFFFFBFBBF\r\n",
      "29\t1\t@SRR1463325.8 HS2:447:C2DFYACXX:5:1101:2251:2171 length=59\r\n",
      "30\t2\tCTAAGGGTGGGTTGATAACCCACAGCAGAAGGCATTCTACCCAATAAGGCGGATACCTC\r\n",
      "31\t3\t+SRR1463325.8 HS2:447:C2DFYACXX:5:1101:2251:2171 length=59\r\n",
      "32\t0\t<<<B<07BBBB'0<<B<BBBBBBBBB77BBBB'<0<BBBB7<B<<BBB<BBB<<B7<<7\r\n"
     ]
    }
   ],
   "source": [
    "awk ' {print (NR \"\\t\" NR%4 \"\\t\" $0)}' testQ32.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SRR1463325.1 HS2:447:C2DFYACXX:5:1101:1336:2178 length=59\r\n",
      "ATGTTAGTAACCGAACCTTCTTCAAAAAGGGCTAAGGGATAAGCTACATACGCAATAAA\r\n",
      "+\r\n",
      "BBBFFFBFFFF0FF0FFBBB0BFFFFIFBF0BBF<B<BF<BB<FFIFFBBBBF######\r\n",
      "@SRR1463325.2 HS2:447:C2DFYACXX:5:1101:1364:2181 length=59\r\n",
      "ACGCATTTATTAGATAAAAGGTCGACGCGGGCTCTGCCCGTTGCTCTGATGATTCATGA\r\n",
      "+\r\n",
      "BBBFFFFFFFFFFFFFIIIFIFIIF'B7FFFBBBFF'7BFBFBFBBFBB<B7<7'0<B<\r\n",
      "@SRR1463325.3 HS2:447:C2DFYACXX:5:1101:1499:2208 length=59\r\n",
      "AGGACCTCTTTAGTATTTTTGTTGATGACCAAAGCACCAGCACCTACAACATGAGAAGC\r\n",
      "+\r\n",
      "BBBFFFFFFFFFFFFFIIIIIIIIIIIIIIIIIIIFIIIFIIIFFIIIIIIIIFFIIIB\r\n",
      "@SRR1463325.4 HS2:447:C2DFYACXX:5:1101:1648:2157 length=59\r\n",
      "NTGTAGAATCTATGTTGAATCACCATTTAGCAGGGCTACTAGGACTTGGGTCCCTTTCT\r\n",
      "+\r\n",
      "#0<BFFFFFFFFFIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIFFIIIFFII\r\n",
      "@SRR1463325.5 HS2:447:C2DFYACXX:5:1101:1776:2228 length=59\r\n",
      "AGCCTCTTTCCGATCTTCTCAACTCCAAGGCTCTCAACGAACTTCCTCACTTCATCATC\r\n",
      "+\r\n",
      "<<0<BFBFBFB0BF<FFFBFFFB<B0BB<<FBFFBFBFBF<FBBFFFFBB<707<B<<7\r\n",
      "@SRR1463325.6 HS2:447:C2DFYACXX:5:1101:1956:2235 length=59\r\n",
      "AGAGTCAATAATTTTATATGAGGAACTACTGAACTCAATCACTTGCTGCCGTTACTCTT\r\n",
      "+\r\n",
      "<B<BBFFBFFF<BFFIIFFFFFFFFFFFFIIFIIIIFIF<FFFIFFFFFIIFF0BBF<F\r\n",
      "@SRR1463325.7 HS2:447:C2DFYACXX:5:1101:2058:2150 length=59\r\n",
      "NTGTTTGAGGGGGAGGTCATAAGCGTCTATACCGTAAAATAGATTTTCGACGAAATGCA\r\n",
      "+\r\n",
      "#0<BFFFFFFFFFFFIFFFIIIIIIFFIFIIIIIFIIFFFFIIIIIIIFFFFFFBFBBF\r\n",
      "@SRR1463325.8 HS2:447:C2DFYACXX:5:1101:2251:2171 length=59\r\n",
      "CTAAGGGTGGGTTGATAACCCACAGCAGAAGGCATTCTACCCAATAAGGCGGATACCTC\r\n",
      "+\r\n",
      "<<<B<07BBBB'0<<B<BBBBBBBBB77BBBB'<0<BBBB7<B<<BBB<BBB<<B7<<7\r\n"
     ]
    }
   ],
   "source": [
    "### Read the file in awk and reproduce it exactly.\n",
    "awk 'BEGIN {separator=\"+\"} {\\\n",
    "       if(NR%4==1) {header=$0}\\\n",
    "             else { if(NR%4==2) {sequence=$0}\\\n",
    "                else { if(NR%4==0) {quality=$0; print (header \"\\n\" sequence \"\\n\" separator \"\\n\" quality )  }}};\\\n",
    "            }' testQ32.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testQ32_IDfilter.fq\r\n"
     ]
    }
   ],
   "source": [
    "### Filter by Identifier.\n",
    "awk 'BEGIN {separator=\"+\";\\\n",
    "     file=ARGV[1]; gsub(/.fa|.fasta|.fastq/,\"\", file); passFile=file\"_IDfilter.fq\"; noFile=file\"_no.fq\"}\\\n",
    "     {\\\n",
    "           if(NR%4==1) {header=$0}\\\n",
    "                 else { if(NR%4==2) {sequence=$0}\\\n",
    "                    else { if(NR%4==0) {quality=$0; \\\n",
    "                    if (header ~ /SRR1463325.1/) {\\\n",
    "                        print (header \"\\n\" sequence \"\\n\" separator \"\\n\" quality)>passFile\\\n",
    "                        }\\\n",
    "          }}};\\\n",
    "     }\\\n",
    "     END {print passFile}' testQ32.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGTTAGTAACCGAACCTTCTTCAAAAAGGGCTAAGGGATAAGCTACATACGCAATAAA\r\n",
      "ACGCATTTATTAGATAAAAGGTCGACGCGGGCTCTGCCCGTTGCTCTGATGATTCATGA\r\n",
      "AGGACCTCTTTAGTATTTTTGTTGATGACCAAAGCACCAGCACCTACAACATGAGAAGC\r\n",
      "NTGTAGAATCTATGTTGAATCACCATTTAGCAGGGCTACTAGGACTTGGGTCCCTTTCT\r\n",
      "AGCCTCTTTCCGATCTTCTCAACTCCAAGGCTCTCAACGAACTTCCTCACTTCATCATC\r\n",
      "AGAGTCAATAATTTTATATGAGGAACTACTGAACTCAATCACTTGCTGCCGTTACTCTT\r\n",
      "NTGTTTGAGGGGGAGGTCATAAGCGTCTATACCGTAAAATAGATTTTCGACGAAATGCA\r\n",
      "CTAAGGGTGGGTTGATAACCCACAGCAGAAGGCATTCTACCCAATAAGGCGGATACCTC\r\n",
      "testQ32_ok.fq\r\n"
     ]
    }
   ],
   "source": [
    "### Print only sequences\n",
    "awk 'BEGIN {separator=\"+\";\\\n",
    "     file=ARGV[1]; gsub(/.fa|.fasta|.fastq/,\"\", file); passFile=file\"_ok.fq\"; noFile=file\"_no.fq\"}\\\n",
    "     {\\\n",
    "           if(NR%4==1) {header=$0}\\\n",
    "                 else { if(NR%4==2) {sequence=$0}\\\n",
    "                    else { if(NR%4==0) {quality=$0; \\\n",
    "                        print (sequence)}\\\n",
    "                        }};\\\n",
    "     }\\\n",
    "     END {print passFile}' testQ32.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testQ32_SequenceFilter.fq\r\n"
     ]
    }
   ],
   "source": [
    "### Filter by sequence.\n",
    "awk 'BEGIN {separator=\"+\";\\\n",
    "     file=ARGV[1]; gsub(/.fa|.fasta|.fastq/,\"\", file); passFile=file\"_SequenceFilter.fq\"; noFile=file\"_no.fq\"}\\\n",
    "     {\\\n",
    "           if(NR%4==1) {header=$0}\\\n",
    "                 else { if(NR%4==2) {sequence=$0}\\\n",
    "                    else { if(NR%4==0) {quality=$0; \\\n",
    "                    if (sequence ~ /[TA]..TTTT/) {\\\n",
    "                        print (header \"\\n\" sequence \"\\n\" separator \"\\n\" quality)>passFile\\\n",
    "                        }\\\n",
    "          }}};\\\n",
    "     }\\\n",
    "     END {print passFile}' testQ32.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random sampling FASTA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read a fasta file in awk\n",
    "awk 'BEGIN{c=0; file=ARGV[1]; gsub(/.fa/,\"\", file); toFile=file\"_upper.fa\";}\\\n",
    "            {if ($1 ~ />/) {c+=1;print $0;} else {print toupper($0)} } END {print c, toFile} ' promoters.fa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\r\n"
     ]
    }
   ],
   "source": [
    "## Get the number of lines. This will be the range.\n",
    "total=`wc -l promoters.fa | awk -F \" \" '{print $1 }'`\n",
    "echo $total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\r\n",
      "39\r\n",
      "78\r\n",
      "79\r\n",
      "91\r\n",
      "19\r\n",
      "33\r\n",
      "76\r\n",
      "27\r\n",
      "55\r\n"
     ]
    }
   ],
   "source": [
    "# use rand() to generate random numbers between 0 and 1.\n",
    "# multiply by a constant M to get numbers between 0 and M.\n",
    "#include 'srand(1);' right at the start to 'seed' the random function.\n",
    "echo \"\" | awk 'BEGIN {i=0;while (i++<10) {print (int(rand()*100)) } exit;}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0t0\r\n",
      "1t1\r\n",
      "0t2\r\n",
      "0t3\r\n",
      "1t4\r\n",
      "2t5\r\n",
      "1t6\r\n",
      "2t7\r\n",
      "1t8\r\n",
      "0t9\r\n",
      "2t10\r\n"
     ]
    }
   ],
   "source": [
    "# Script to generate random numbers and count the number of occurences wach one is sampled.\n",
    "echo \"\" | awk 'BEGIN {srand(); i=0;while (i++<10)\\\n",
    "         {x=int(rand()*10 + 0.5);y[x]++;} \\\n",
    "         for (i=0;i<=10;i++) {printf(\"%dt%d\\n\",y[i],i);}exit;}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 28\r\n",
      "1 8\r\n",
      "2 29\r\n",
      "1 10\r\n",
      "1 13\r\n",
      "1 15\r\n",
      "1 31\r\n",
      "1 33\r\n",
      "1 20\r\n"
     ]
    }
   ],
   "source": [
    "## Random number generator doesn't have a function to avoid replacement \n",
    "# ie, 23,29 and 33 appear twice\n",
    "echo \"\" | awk 'BEGIN { ranVar[\"\"]=0;srand(1); for (i = 1; i <= 10; i++) { v=int(36 * rand()+1); ranVar[v]++}} \\\n",
    "               END {for (i in ranVar) {if (i != \"\") {print ranVar[i], i;}}}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 23\r\n",
      "1 28\r\n",
      "1 8\r\n",
      "1 29\r\n",
      "1 10\r\n",
      "1 13\r\n",
      "1 15\r\n",
      "1 18\r\n",
      "1 31\r\n",
      "1 33\r\n",
      "1 20\r\n"
     ]
    }
   ],
   "source": [
    "## We can create our own random number generator without replacement.\n",
    "# Instead of 29 appearing twice, we get 18. We can use associative arrays to prove this works:\n",
    "maxV=36\n",
    "N=11\n",
    "minV=${minV:-1}\n",
    "minV=1\n",
    "#######\n",
    "## Algorithm: \n",
    "### srand() for seed.\n",
    "### Start a loop to generate N random numbers\n",
    "### 1. on each iteration generate a random number between 0 and max:  \n",
    "###### This works as follows:\n",
    "######### call the rand() function  (this generates a number between 0 and 1)\n",
    "######### Multiply it by the max value and get the integer part it with int(). \n",
    "######### If you want to generate values between a MIN and MAX, add the MIN, and multiply  rand() by the range (max-min) + 1\n",
    "### 2a. If the value already exists go back one step in the counter and generate a new value.\n",
    "### 2b. If the value hasn't been generated save it into an array.\n",
    "#########\n",
    "echo \"\" | awk 'BEGIN { if ('$N' > '$maxV'-'$minV') {print (\"Number of unique values to be generated exceeds the possible range\"); exit;} srand(1); \\\n",
    "                    for (i = 1; i <= '$N'; i++) {\\\n",
    "                    v=int('$minV'+rand()*('$maxV'-'$minV'+1)); if(v in ranVar) i-- ; else { ranVar[v]++ }}}\\\n",
    "                    END {for (i in ranVar) { print ranVar[i], i;} }'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\r\n",
      "file3\t3\t6\t20\r\n",
      "line_a\t12\t13\t144\r\n",
      "line_b\t15\t16\t177\r\n"
     ]
    }
   ],
   "source": [
    "## We can use this program to randomly sample a table.\n",
    "file=\"cols.txt\"\n",
    "maxV=`wc -l $file | awk -F \" \" '{print $1 }'`\n",
    "echo $maxV\n",
    "######\n",
    "N=3 #Max number of numbers being sampled\n",
    "minV=${minV:-1}\n",
    "minV=1\n",
    "### We can now use this random list to sample a file. \n",
    "awk 'BEGIN { if ('$N' > '$maxV'-'$minV') {print (\"Number of unique values to be generated exceeds the possible range\"); exit;} srand(1); \\\n",
    "                    for (i = 1; i <= '$N'; i++) {\\\n",
    "                    v=int('$minV'+rand()*('$maxV'-'$minV'+1)); if(v in ranVar) i-- ; else { ranVar[v]++ }}}\\\n",
    "                    {if (NR in ranVar) {print ($0)} }' $file\n",
    "                    #END {for (i in ranVar) { print ranVar[i], i;} }'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "file=\"cols.txt\"\n",
    "maxV=`wc -l $file | awk -F \" \" '{print $1 }'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\r\n",
      "184\r\n",
      "86\r\n",
      "174\r\n",
      "168\r\n",
      "promoters_RanSample.fa\r\n"
     ]
    }
   ],
   "source": [
    "## We can use this program to randomly sample a FASTA file.\n",
    "# This program introduces a modification in the algorithm:\n",
    "## Divide Max by 2 (Not all lines are to be sampled,).\n",
    "file=\"promoters.fa\"\n",
    "maxV=`wc -l $file | awk -F \" \" '{print $1 }'`\n",
    "echo $maxV\n",
    "######\n",
    "N=4 #Max number of numbers being sampled\n",
    "minV=${minV:-1}\n",
    "minV=0\n",
    "### We can now use this random list to sample a file. \n",
    "awk 'BEGIN { maxPossible=int( '$maxV'/2) + 1;\\\n",
    "        file=ARGV[1]; gsub(/.fa/,\"\", file); toFile=file\"_RanSample.fa\";\\\n",
    "        if ('$N' > maxPossible-'$minV') {print (\"Number of unique values to be generated exceeds the possible range\"); exit;}\\\n",
    "        srand(1); \\\n",
    "        for (i = 1; i <= '$N'; i++) {\\\n",
    "            v=int('$minV'+rand()*('$maxV'-'$minV'+1));\\\n",
    "                  if(v%2==1 || v in ranVar) i-- ; else { ranVar[v]++ ; print (v)}}}\\\n",
    "        {if ($1 ~ />/) { tmp=$0;} ;\\\n",
    "        if (NR in ranVar) {print tmp \"\\n\" toupper($0) > toFile }} END {print toFile}' $file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Random Sampling FASTQ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\r\n",
      "16\r\n",
      "12\r\n",
      "20\r\n",
      "24\r\n"
     ]
    }
   ],
   "source": [
    "## We can use this program to randomly sample a FASTA file.\n",
    "# This program introduces a modification in the algorithm:\n",
    "## Divide Max by 4.\n",
    "file=\"testQ32.fastq\"\n",
    "maxV=`wc -l $file | awk -F \" \" '{print $1 }'`\n",
    "echo $maxV\n",
    "######\n",
    "N=4 #Max number of numbers being sampled\n",
    "minV=${minV:-1}\n",
    "minV=1\n",
    "### We can now use this random list to sample a file. \n",
    "awk 'BEGIN { maxPossible=int( '$maxV'/4) + 1;\\\n",
    "             separator=\"+\";\\\n",
    "        file=ARGV[1]; gsub(/.fq|.fastq/,\"\", file); toFile=file\"_RanSample.fq\";\\\n",
    "        if ('$N' > maxPossible-'$minV') {print (\"Number of unique values to be generated exceeds the possible range\"); exit;}\\\n",
    "        srand(); \\\n",
    "        for (i = 1; i <= '$N'; i++) {\\\n",
    "            v=int('$minV'+rand()*('$maxV'-'$minV'+1));\\\n",
    "                  if(v%4!=0 || v in ranVar) i-- ; else { ranVar[v]++ ; print (v)}}}\\\n",
    "    {\\\n",
    "        if(NR%4==1) {header=$0}\\\n",
    "                 else { if(NR%4==2) {sequence=$0}\\\n",
    "                    else { if(NR%4==0) {quality=$0;\\\n",
    "        if (NR in ranVar) {print (NR \"\\t\" header \"\\n\" sequence \"\\n\" separator \"\\n\" quality ) > toFile}\\\n",
    "       }}}\\\n",
    "    }' $file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### More thoroguh guides and tutorials:\n",
    "\n",
    "* http://www.grymoire.com/Unix/Awk.html\n",
    "\n",
    "### Regular expressions:\n",
    "\n",
    "* https://www.cheatography.com/davechild/cheat-sheets/regular-expressions/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
